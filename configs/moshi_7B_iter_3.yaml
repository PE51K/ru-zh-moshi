# data
data:
  eval_data: './dataset/finetune_2/finetune_data/val.jsonl'
  shuffle: true
  train_data: './dataset/finetune_2/finetune_data/train.jsonl'

# model
moshi_paths:
  hf_repo_id: "kyutai/moshiko-pytorch-bf16"

full_finetuning: false
lora:
  enable: true
  rank: 128
  scaling: 2.
  ft_embed: false

first_codebook_weight_multiplier: 100.
text_padding_weight: .5

# optim
duration_sec: 100
batch_size: 8
max_steps: 1000
gradient_checkpointing: true
optim:
  lr: 2e-6
  weight_decay: 0.1
  pct_start: 0.05

# other
seed: 0
log_freq: 1
eval_freq: 100
do_eval: true
do_ckpt: true
ckpt_freq: 100

save_adapters: true
num_ckpt_keep: 10

run_dir: "./weights/finetune_5"

# wandb
wandb:
  project: "moshi-finetune"
  run_name: "finetune_5"
  key: "1c2c36915a610180e6884b71d2a6eadc7a0176b2"
  offline: False
