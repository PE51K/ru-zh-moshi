{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/gregory1m/Code/spbu-diploma/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " > Using model: xtts\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
                        "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
                        "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
                        "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "from TTS.api import TTS\n",
                "import torch.serialization\n",
                "\n",
                "# Override the torch.load function to use weights_only=False by default\n",
                "# Only do this if you trust the source of the checkpoint\n",
                "original_torch_load = torch.load\n",
                "torch.load = lambda f, map_location=None, pickle_module=torch.serialization.pickle, **kwargs: original_torch_load(\n",
                "    f, map_location=map_location, pickle_module=pickle_module, weights_only=False, **kwargs\n",
                ")\n",
                "\n",
                "# Initialize TTS model\n",
                "tts = TTS(\"omogr/xtts-ru-ipa\").to(\"cuda\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Selected message: –í –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –º–æ–≥—É—Ç –≤–∞—Ä—å–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∏—Ç—É–∞—Ü–∏–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫\\. –í–æ—Ç –æ—Å...\n",
                        "Processing with voice: voice6.wav\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments:   0%|          | 0/17 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.28it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice6.wav.wav\n",
                        "Processing with voice: voice1.wav\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.42it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice1.wav.wav\n",
                        "Processing with voice: voice0.mp3\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:13<00:00,  1.27it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice0.mp3.wav\n",
                        "Processing with voice: voice4.wav\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.48it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice4.wav.wav\n",
                        "Processing with voice: voice5.wav\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.43it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice5.wav.wav\n",
                        "Processing with voice: voice8.wav\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:14<00:00,  1.17it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice8.wav.wav\n",
                        "Processing with voice: voice7.wav\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:15<00:00,  1.12it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice7.wav.wav\n",
                        "Processing with voice: voice3.wav\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.31it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice3.wav.wav\n",
                        "Processing with voice: voice2.wav\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.34it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice2.wav.wav\n",
                        "Processing with voice: voice9.wav\n",
                        "Processing with language segments...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing segments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.36it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully generated mixed language audio: ../dataset/sample_audio/mixed_lang_voice9.wav.wav\n",
                        "Audio generation complete.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "from TTS.api import TTS\n",
                "import json\n",
                "import os\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "import logging\n",
                "import soundfile as sf\n",
                "import sys\n",
                "\n",
                "# Configure minimal logging - more aggressive suppression\n",
                "logging.basicConfig(level=logging.ERROR)\n",
                "\n",
                "# Silence TTS-specific logging\n",
                "logging.getLogger('TTS').setLevel(logging.ERROR)\n",
                "logging.getLogger('TTS.utils.synthesizer').setLevel(logging.ERROR)\n",
                "\n",
                "# Suppress stdout temporarily during TTS operations\n",
                "class NullWriter:\n",
                "    def write(self, s):\n",
                "        pass\n",
                "    def flush(self):\n",
                "        pass\n",
                "\n",
                "# Define paths\n",
                "jsonl_file = \"../dataset/text_cleaned/data.jsonl\"\n",
                "voices_path = \"../dataset/voices\"\n",
                "output_path = \"../dataset/sample_audio\"\n",
                "\n",
                "# Ensure output directory exists\n",
                "os.makedirs(output_path, exist_ok=True)\n",
                "\n",
                "# Read all conversations from the JSONL file\n",
                "conversations = []\n",
                "with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
                "    for line in f:\n",
                "        conversations.append(json.loads(line))\n",
                "\n",
                "# Select a specific conversation and message\n",
                "conversation = conversations[9000]\n",
                "selected_message = conversation[1]\n",
                "sample_text = selected_message[\"content\"]\n",
                "\n",
                "print(f\"Selected message: {sample_text[:100]}...\")\n",
                "\n",
                "for voice_filename in os.listdir(voices_path):\n",
                "    voice_path = os.path.join(voices_path, voice_filename)\n",
                "    print(f\"Processing with voice: {voice_filename}\")\n",
                "\n",
                "    # Process the message with language segments if available\n",
                "    if \"language_segments\" in selected_message and selected_message[\"language_segments\"]:\n",
                "        print(\"Processing with language segments...\")\n",
                "        output_file = os.path.join(output_path, f\"mixed_lang_{voice_filename}.wav\")\n",
                "        \n",
                "        # Generate speech for each segment directly without saving intermediate files\n",
                "        audio_segments = []\n",
                "        sample_rate = None\n",
                "        \n",
                "        for idx, segment in enumerate(tqdm(selected_message[\"language_segments\"], desc=\"Processing segments\")):\n",
                "            segment_text = segment[\"text\"].strip()\n",
                "            segment_lang = segment[\"lang\"]\n",
                "            \n",
                "            # Skip empty segments\n",
                "            if not segment_text:\n",
                "                continue\n",
                "            \n",
                "            # Capture and suppress stdout during TTS generation\n",
                "            original_stdout = sys.stdout\n",
                "            sys.stdout = NullWriter()\n",
                "            \n",
                "            try:\n",
                "                # Generate speech directly as numpy array\n",
                "                segment_audio = tts.tts(\n",
                "                    text=segment_text,\n",
                "                    speaker_wav=voice_path,\n",
                "                    language=segment_lang\n",
                "                )\n",
                "                \n",
                "                # Store the sample rate from the first segment\n",
                "                if sample_rate is None:\n",
                "                    sample_rate = tts.synthesizer.output_sample_rate\n",
                "                \n",
                "                audio_segments.append(segment_audio)\n",
                "            except Exception as e:\n",
                "                print(f\"Error processing segment {idx}: {e}\")\n",
                "            finally:\n",
                "                # Restore stdout\n",
                "                sys.stdout = original_stdout\n",
                "        \n",
                "        # Concatenate all audio segments in memory\n",
                "        if audio_segments:\n",
                "            # Concatenate all segments using numpy\n",
                "            concat_audio = np.concatenate(audio_segments)\n",
                "            \n",
                "            # Save the final audio file\n",
                "            sf.write(output_file, concat_audio, sample_rate)\n",
                "            \n",
                "            print(f\"Successfully generated mixed language audio: {output_file}\")\n",
                "        else:\n",
                "            print(\"No segments were processed successfully.\")\n",
                "\n",
                "    else:\n",
                "        # Process the whole message as a single language (Russian)\n",
                "        print(\"Processing as a single language...\")\n",
                "        output_file = os.path.join(output_path, f\"single_lang_{voice_filename}.wav\")\n",
                "        \n",
                "        # Capture and suppress stdout during TTS generation\n",
                "        original_stdout = sys.stdout\n",
                "        sys.stdout = NullWriter()\n",
                "        \n",
                "        try:\n",
                "            # Generate the audio directly\n",
                "            audio = tts.tts(\n",
                "                text=sample_text,\n",
                "                speaker_wav=voice_path,\n",
                "                language=\"ru\"\n",
                "            )\n",
                "            \n",
                "            # Restore stdout\n",
                "            sys.stdout = original_stdout\n",
                "            \n",
                "            # Save the audio\n",
                "            sf.write(output_file, audio, tts.synthesizer.output_sample_rate)\n",
                "            \n",
                "            print(f\"Successfully generated audio: {output_file}\")\n",
                "        except Exception as e:\n",
                "            # Restore stdout\n",
                "            sys.stdout = original_stdout\n",
                "            print(f\"Error generating audio: {e}\")\n",
                "\n",
                "print(\"Audio generation complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing conversations:   0%|          | 3/10006 [03:56<205:34:31, 73.98s/it]"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "from TTS.api import TTS\n",
                "import json\n",
                "import os\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "import logging\n",
                "import soundfile as sf\n",
                "import sys\n",
                "import random\n",
                "\n",
                "# Configure minimal logging - aggressive suppression\n",
                "logging.basicConfig(level=logging.ERROR)\n",
                "logging.getLogger('TTS').setLevel(logging.ERROR)\n",
                "logging.getLogger('TTS.utils.synthesizer').setLevel(logging.ERROR)\n",
                "\n",
                "# Suppress stdout temporarily during TTS operations\n",
                "class NullWriter:\n",
                "    def write(self, s):\n",
                "        pass\n",
                "    def flush(self):\n",
                "        pass\n",
                "\n",
                "# Define paths\n",
                "jsonl_file = \"../dataset/text_cleaned/data.jsonl\"\n",
                "voices_path = \"../dataset/voices\"\n",
                "output_path = \"../dataset/audio\"\n",
                "\n",
                "# Ensure output directory exists\n",
                "os.makedirs(output_path, exist_ok=True)\n",
                "\n",
                "# Read all conversations from the JSONL file\n",
                "conversations = []\n",
                "with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
                "    for line in f:\n",
                "        conversations.append(json.loads(line))\n",
                "\n",
                "# Get list of all available voice files\n",
                "available_voices = os.listdir(voices_path)\n",
                "\n",
                "# Process all conversations with minimal logging\n",
                "for conversation_idx, conversation in enumerate(tqdm(conversations, desc=\"Processing conversations\")):\n",
                "    try:\n",
                "        # Create a directory for this conversation\n",
                "        conversation_dir = os.path.join(output_path, f\"conversation_{conversation_idx}\")\n",
                "        os.makedirs(conversation_dir, exist_ok=True)\n",
                "        \n",
                "        # Select a random speaker pair for this conversation\n",
                "        user_voice = random.choice(available_voices)\n",
                "        assistant_voice = random.choice(available_voices)\n",
                "        \n",
                "        # Map roles to voice files\n",
                "        role_to_voice = {\n",
                "            'user': os.path.join(voices_path, user_voice),\n",
                "            'assistant': os.path.join(voices_path, assistant_voice)\n",
                "        }\n",
                "        \n",
                "        # Process each turn in the conversation\n",
                "        for turn_idx, message in enumerate(conversation):\n",
                "            role = message.get(\"role\", \"\")\n",
                "            \n",
                "            # Skip if role is not defined or not in our mapping\n",
                "            if not role or role not in role_to_voice:\n",
                "                continue\n",
                "                \n",
                "            # Get the appropriate voice for this role\n",
                "            voice_path = role_to_voice[role]\n",
                "            \n",
                "            # Define output filename (1-indexed turn number)\n",
                "            output_file = os.path.join(conversation_dir, f\"{turn_idx+1}_{role}.wav\")\n",
                "            \n",
                "            # Skip if file already exists\n",
                "            if os.path.exists(output_file):\n",
                "                continue\n",
                "                \n",
                "            # Process with language segments if available\n",
                "            if \"language_segments\" in message and message[\"language_segments\"]:\n",
                "                audio_segments = []\n",
                "                sample_rate = None\n",
                "                \n",
                "                # Process each language segment\n",
                "                for segment in message[\"language_segments\"]:\n",
                "                    segment_text = segment[\"text\"].strip()\n",
                "                    segment_lang = segment[\"lang\"]\n",
                "                    \n",
                "                    # Skip empty segments\n",
                "                    if not segment_text:\n",
                "                        continue\n",
                "                    \n",
                "                    # Capture and suppress stdout during TTS generation\n",
                "                    original_stdout = sys.stdout\n",
                "                    sys.stdout = NullWriter()\n",
                "                    \n",
                "                    try:\n",
                "                        # Generate speech directly as numpy array\n",
                "                        segment_audio = tts.tts(\n",
                "                            text=segment_text,\n",
                "                            speaker_wav=voice_path,\n",
                "                            language=segment_lang\n",
                "                        )\n",
                "                        \n",
                "                        # Store the sample rate from the first segment\n",
                "                        if sample_rate is None:\n",
                "                            sample_rate = tts.synthesizer.output_sample_rate\n",
                "                        \n",
                "                        audio_segments.append(segment_audio)\n",
                "                    except Exception:\n",
                "                        # Silent exception handling\n",
                "                        pass\n",
                "                    finally:\n",
                "                        # Restore stdout\n",
                "                        sys.stdout = original_stdout\n",
                "                \n",
                "                # Concatenate all audio segments in memory\n",
                "                if audio_segments:\n",
                "                    # Concatenate all segments using numpy\n",
                "                    concat_audio = np.concatenate(audio_segments)\n",
                "                    \n",
                "                    # Save the final audio file\n",
                "                    sf.write(output_file, concat_audio, sample_rate)\n",
                "            \n",
                "            else:\n",
                "                # Process the whole message as a single language (default to Russian)\n",
                "                text = message.get(\"content\", \"\").strip()\n",
                "                \n",
                "                if not text:\n",
                "                    continue\n",
                "                \n",
                "                # Capture and suppress stdout during TTS generation\n",
                "                original_stdout = sys.stdout\n",
                "                sys.stdout = NullWriter()\n",
                "                \n",
                "                try:\n",
                "                    # Generate the audio directly\n",
                "                    audio = tts.tts(\n",
                "                        text=text,\n",
                "                        speaker_wav=voice_path,\n",
                "                        language=\"ru\"  # Default to Russian\n",
                "                    )\n",
                "                    \n",
                "                    # Save the audio\n",
                "                    sf.write(output_file, audio, tts.synthesizer.output_sample_rate)\n",
                "                except Exception:\n",
                "                    # Silent exception handling\n",
                "                    pass\n",
                "                finally:\n",
                "                    # Restore stdout\n",
                "                    sys.stdout = original_stdout\n",
                "                    \n",
                "    except Exception:\n",
                "        # Silent exception handling for the entire conversation\n",
                "        continue\n",
                "\n",
                "print(\"Audio generation complete.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.21"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
